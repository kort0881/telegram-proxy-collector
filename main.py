import requests
import re
import socket
import concurrent.futures
import time
from urllib.parse import urlparse, parse_qs
from collections import Counter
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
SOURCES = [
    "https://raw.githubusercontent.com/SoliSpirit/mtproto/master/proxies.txt",
    "https://raw.githubusercontent.com/hookzof/socks5_list/master/tg/mtproto.json",
    "https://raw.githubusercontent.com/soroushmirzaei/telegram-proxies-collector/main/proxies.txt",
    "https://raw.githubusercontent.com/MrPotat-00/MTProtoProxiesScraper/main/proxies.txt",
    "https://raw.githubusercontent.com/DigneZzZ/telegram-mtproto-proxies/master/proxy_list.txt"
]

OUTPUT_FILE = "proxy_list.txt"
TIMEOUT = 3  # –£–≤–µ–ª–∏—á–µ–Ω —Ç–∞–π–º-–∞—É—Ç
MAX_WORKERS = 100  # –ë–æ–ª—å—à–µ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è –±—ã—Å—Ç—Ä–æ—Ç—ã

# –°–ø–∏—Å–æ–∫ –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤ Fake-TLS –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏
QUALITY_DOMAINS = [
    'microsoft.com', 'google.com', 'cloudflare.com', 
    'azure.com', 'amazon.com', 'bing.com'
]

def parse_proxy(line):
    """–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è –≤—Å–µ—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤ –ø—Ä–æ–∫—Å–∏"""
    # –§–æ—Ä–º–∞—Ç tg://
    tg_pattern = r"tg://proxy\?(.+)"
    match = re.search(tg_pattern, line)
    if match:
        params = parse_qs(match.group(1))
        server = params.get('server', [None])[0]
        port = params.get('port', [None])[0]
        secret = params.get('secret', [None])[0]
        if server and port and secret:
            return server, int(port), secret
    
    # –§–æ—Ä–º–∞—Ç t.me
    tme_pattern = r"t\.me/proxy\?(.+)"
    match = re.search(tme_pattern, line)
    if match:
        params = parse_qs(match.group(1))
        server = params.get('server', [None])[0]
        port = params.get('port', [None])[0]
        secret = params.get('secret', [None])[0]
        if server and port and secret:
            return server, int(port), secret
    
    # –§–æ—Ä–º–∞—Ç JSON-–æ–±—ä–µ–∫—Ç–∞ –≤ —Å—Ç—Ä–æ–∫–µ
    json_pattern = r'(?:server|host)["\s:]+([^"&\s]+).*?port["\s:]+(\d+).*?secret["\s:]+([A-Za-z0-9]+)'
    match = re.search(json_pattern, line, re.IGNORECASE)
    if match:
        return match.group(1), int(match.group(2)), match.group(3)
    
    return None

def decode_secret_domain(secret):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–æ–º–µ–Ω –∏–∑ Fake-TLS —Å–µ–∫—Ä–µ—Ç–∞"""
    if not secret.startswith('ee'):
        return None
    try:
        # ee + hex-encoded domain
        hex_domain = secret[2:]
        # –£–±–∏—Ä–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ—Å–ª–µ –¥–æ–º–µ–Ω–∞
        hex_domain = hex_domain[:hex_domain.find('00')] if '00' in hex_domain else hex_domain
        domain = bytes.fromhex(hex_domain).decode('utf-8', errors='ignore')
        return domain
    except:
        return None

def is_quality_secret(secret):
    """–†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–µ–∫—Ä–µ—Ç–∞"""
    if not secret or len(secret) < 4:
        return False
    
    # Fake-TLS (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç)
    if secret.startswith("ee"):
        domain = decode_secret_domain(secret)
        if domain:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –¥–æ–º–µ–Ω –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∏–º–µ–Ω–∞
            for quality_domain in QUALITY_DOMAINS:
                if quality_domain in domain.lower():
                    return True
        return True  # –í—Å–µ —Ä–∞–≤–Ω–æ –ø—Ä–∏–Ω–∏–º–∞–µ–º Fake-TLS
    
    # Random padding (–º–µ–Ω–µ–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ)
    if secret.startswith("dd"):
        return True
    
    return False

def get_secret_score(secret):
    """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–µ–∫—Ä–µ—Ç–∞ (—á–µ–º –≤—ã—à–µ, —Ç–µ–º –ª—É—á—à–µ)"""
    score = 0
    
    if secret.startswith("ee"):
        score += 10
        domain = decode_secret_domain(secret)
        if domain:
            for quality_domain in QUALITY_DOMAINS:
                if quality_domain in domain.lower():
                    score += 5
                    break
    elif secret.startswith("dd"):
        score += 5
    
    return score

def check_port_advanced(host, port):
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Ä—Ç–∞ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π"""
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ DNS
        socket.gethostbyname(host)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(TIMEOUT)
        result = sock.connect_ex((host, port))
        sock.close()
        
        return result == 0
    except:
        return False

def check_response_time(host, port):
    """–ò–∑–º–µ—Ä—è–µ—Ç –≤—Ä–µ–º—è –æ—Ç–∫–ª–∏–∫–∞ –ø—Ä–æ–∫—Å–∏"""
    try:
        start = time.time()
        with socket.create_connection((host, port), timeout=TIMEOUT):
            return time.time() - start
    except:
        return float('inf')

def process_source(url):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ —Å retry –ª–æ–≥–∏–∫–æ–π"""
    proxies = []
    max_retries = 3
    
    for attempt in range(max_retries):
        try:
            resp = requests.get(url, timeout=15, headers={
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            })
            text = resp.text
            
            # JSON —Ñ–æ—Ä–º–∞—Ç
            if url.endswith(".json"):
                try:
                    data = resp.json()
                    if isinstance(data, list):
                        for item in data:
                            host = item.get('host') or item.get('server')
                            port = item.get('port')
                            secret = item.get('secret')
                            if host and port and secret:
                                proxies.append((host, int(port), secret))
                except Exception as e:
                    logger.warning(f"JSON parse error for {url}: {e}")
            
            # –¢–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç
            for line in text.splitlines():
                p = parse_proxy(line)
                if p:
                    proxies.append(p)
            
            logger.info(f"‚úì {url}: –Ω–∞–π–¥–µ–Ω–æ {len(proxies)} –ø—Ä–æ–∫—Å–∏")
            return proxies
            
        except Exception as e:
            logger.warning(f"–ü–æ–ø—ã—Ç–∫–∞ {attempt+1}/{max_retries} –¥–ª—è {url} –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
            time.sleep(2)
    
    return proxies

def validate_proxy(proxy):
    """–ü–æ–ª–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –ø—Ä–æ–∫—Å–∏"""
    host, port, secret = proxy
    
    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–µ–∫—Ä–µ—Ç–∞
    if not is_quality_secret(secret):
        return None
    
    # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏
    if not check_port_advanced(host, port):
        return None
    
    # 3. –ò–∑–º–µ—Ä–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–∫–ª–∏–∫–∞
    response_time = check_response_time(host, port)
    
    # 4. –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
    quality_score = get_secret_score(secret)
    
    link = f"tg://proxy?server={host}&port={port}&secret={secret}"
    
    return {
        'link': link,
        'response_time': response_time,
        'quality_score': quality_score,
        'host': host
    }

def main():
    logger.info("üöÄ –ù–∞—á–∏–Ω–∞—é —Å–±–æ—Ä MTProto –ø—Ä–æ–∫—Å–∏...")
    
    all_candidates = []
    
    # 1. –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π —Å–±–æ—Ä –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
    with concurrent.futures.ThreadPoolExecutor(max_workers=len(SOURCES)) as executor:
        futures = [executor.submit(process_source, url) for url in SOURCES]
        for future in concurrent.futures.as_completed(futures):
            all_candidates.extend(future.result())
    
    # 2. –£–¥–∞–ª–µ–Ω–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
    unique_candidates = list(set(all_candidates))
    logger.info(f"üìä –ù–∞–π–¥–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤: {len(unique_candidates)}")
    
    # 3. –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
    valid_proxies = []
    logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞...")
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(validate_proxy, p): p for p in unique_candidates}
        
        completed = 0
        for future in concurrent.futures.as_completed(futures):
            completed += 1
            if completed % 50 == 0:
                logger.info(f"–ü—Ä–æ–≤–µ—Ä–µ–Ω–æ: {completed}/{len(unique_candidates)}")
            
            result = future.result()
            if result:
                valid_proxies.append(result)
    
    # 4. –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É –∏ —Å–∫–æ—Ä–æ—Å—Ç–∏
    valid_proxies.sort(key=lambda x: (-x['quality_score'], x['response_time']))
    
    logger.info(f"‚úÖ –í–∞–ª–∏–¥–Ω—ã—Ö –ø—Ä–æ–∫—Å–∏: {len(valid_proxies)}")
    
    # 5. –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    if valid_proxies:
        avg_response = sum(p['response_time'] for p in valid_proxies if p['response_time'] != float('inf')) / len(valid_proxies)
        logger.info(f"üìà –°—Ä–µ–¥–Ω–∏–π –æ—Ç–∫–ª–∏–∫: {avg_response:.2f}—Å")
        
        # –¢–æ–ø-10 –¥–æ–º–µ–Ω–æ–≤ —Ö–æ—Å—Ç–æ–≤
        host_counter = Counter(p['host'] for p in valid_proxies)
        logger.info(f"üèÜ –¢–æ–ø —Ö–æ—Å—Ç–æ–≤: {host_counter.most_common(5)}")
    
    # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        f.write("\n".join(p['link'] for p in valid_proxies))
    
    logger.info(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {OUTPUT_FILE}")

if __name__ == "__main__":
    main()
